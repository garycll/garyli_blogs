{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sgd_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUP0ywod6c6obbw30aOjl1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garycll/blogs/blob/main/sgd_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbHetN10jDSV"
      },
      "source": [
        "# Neural network from scratch with Python and PyTorch's gradient calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0lT6rUjkCY1"
      },
      "source": [
        "Deep learning libraries such as PyTorch and TensorFlow make it easy for us to build a deep neural network without knowing its implementation details. However, to gain a better understanding of how a neural network works, it is useful to build one from scratch.\n",
        "\n",
        "This notebook implements stochastic gradient descent (SGD, the optimization algorithm for training a neural network) with Python and apply it to train a neural network. To apply the same SGD codes to different network architectures, we use Pytorch to calculate graidents (and that's the only Pytorch functionality I use). We illustrate this advantage by applying SGD to two network architectures, namely a linear model and a simple network with 2 layers.\n",
        "\n",
        "To demonstrate the codes in this notebook, we use the famous [MNIST](http://yann.lecun.com/exdb/mnist/) data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1-BLDT4pJlx"
      },
      "source": [
        "# Reading the MNIST data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7fbk2xHpRod"
      },
      "source": [
        "First of all, we read the MNIST data and split it into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axbb7erQUXzb"
      },
      "source": [
        "import torch\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhGTb0OVgzGE"
      },
      "source": [
        "orig_x, orig_y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5jc2IN3rfK8"
      },
      "source": [
        "x = (orig_x/255).astype('float32') # divide by 255 to normalize the pixel values between 0 and 1\n",
        "y = orig_y.astype('long')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD3H4Jhxi9wL"
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ_qV5AGOLct"
      },
      "source": [
        "train_x = torch.from_numpy(train_x)\n",
        "valid_x = torch.from_numpy(valid_x)\n",
        "train_y = torch.from_numpy(train_y)\n",
        "valid_y = torch.from_numpy(valid_y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxWLR-IzMmxo",
        "outputId": "6856cd11-4018-4146-fb29-4f95c1cfdce7"
      },
      "source": [
        "print(f'There are {train_x.shape[0]} training samples and {valid_x.shape[0]} validation samples')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 59500 training samples and 10500 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uqsY7ZWOsNU"
      },
      "source": [
        "# Neural Network and SDG on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTTP9vCesWVU"
      },
      "source": [
        "A key component in neural network is the loss function. In this notebook, we use cross entropy as the loss function for a multi-class classification problem since MNIST has 10 classes.\n",
        "\n",
        "We implement cross entropy from scratch instead of using F.cross_entropy in Pytorch. To improve numerical stability in the calculation of cross entropy, we use the LogSumExp trick. I copied [the codes](https://github.com/fastai/course-v3/blob/master/nbs/dl2/03_minibatch_training.ipynb) from Jeremy Howard (see the Cross Entropy Loss section in his notebook for details)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5DOYhV_5CAs"
      },
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]\n",
        "  return m + (x - m[:, None]).exp().sum(-1).log()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2986PWyvzm"
      },
      "source": [
        "def log_softmax(x):\n",
        "    return x - logsumexp(x).unsqueeze(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTQJu7kzVZA"
      },
      "source": [
        "def nll(predictions, target):\n",
        "    return -predictions[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU3MHe3JQFf-"
      },
      "source": [
        "def mnist_loss(predictions, targets):\n",
        "    # equivalent to F.cross_entropy(predictions, targets) in Pytorch\n",
        "    # return F.cross_entropy(predictions, targets)\n",
        "    return nll(log_softmax(predictions), targets)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka3_lX73raVD"
      },
      "source": [
        "Below are the codes of neural network and SDG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpbEdhjgP6_v"
      },
      "source": [
        "def init_params(size, std=1.0):\n",
        "    return (torch.randn(size)*std).requires_grad_()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPF0Va2pQEAi"
      },
      "source": [
        "def linear1(xb, params):\n",
        "    weights, bias = params\n",
        "    return xb@weights + bias"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm9TiYu2QI01"
      },
      "source": [
        "def batch_accuracy(xb, yb):\n",
        "    correct = (torch.argmax(xb, dim=1) == yb)\n",
        "    return correct.float().mean()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMIUaeK4QKXy"
      },
      "source": [
        "def validate_epoch(model, params, dataloader):\n",
        "    accs = [batch_accuracy(model(xb, params), yb) for xb, yb in dataloader]\n",
        "    return round(torch.stack(accs).mean().item(), 4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpFsZ9htQMYY"
      },
      "source": [
        "def train_epoch(model, lr, params, dataloader):\n",
        "    for xb, yb in dataloader:\n",
        "        preds = model(xb, params)\n",
        "        loss = mnist_loss(preds, yb)\n",
        "        loss.backward()\n",
        "        for p in params:\n",
        "            p.data -= p.grad * lr\n",
        "            p.grad.zero_()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV33vHMWQNuI"
      },
      "source": [
        "def train_model(model, epochs, lr, params, train_dl, valid_dl):\n",
        "    for i in range(epochs):\n",
        "        train_epoch(model, lr, params, train_dl)\n",
        "        print(f'{i+1}: accuracy={validate_epoch(model, params, valid_dl):.4f}')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTdmk-guCFf"
      },
      "source": [
        "Below I implement a simple data loader so we can train the model with mini batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2rn6CLrQPLX"
      },
      "source": [
        "class SimpleDataLoader:\n",
        "    def __init__(self, x, y, batch_size=256):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def __iter__(self):\n",
        "        self.idx = 0\n",
        "        return self\n",
        "        \n",
        "    def __next__(self):\n",
        "        size = len(self.y)\n",
        "        if self.idx < size and self.idx + self.batch_size < size:\n",
        "            x = self.x[self.idx : self.idx + self.batch_size]\n",
        "            y = self.y[self.idx : self.idx + self.batch_size]\n",
        "        elif self.idx < size:\n",
        "            x = self.x[self.idx :]\n",
        "            y = self.y[self.idx :]\n",
        "        else:\n",
        "            raise StopIteration\n",
        "        self.idx += self.batch_size\n",
        "        return (x, y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hmu-jXBQRNR"
      },
      "source": [
        "train_dl = iter(SimpleDataLoader(train_x, train_y, 256))\n",
        "valid_dl = iter(SimpleDataLoader(valid_x, valid_y, 256))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Ly3rSatvf1"
      },
      "source": [
        "# A linear model using SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HDHFZB7QTHO"
      },
      "source": [
        "lr = 1\n",
        "weights = init_params((28*28, 10))\n",
        "bias = init_params(10)\n",
        "params = weights, bias"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNqrbO6zQzdw",
        "outputId": "fe1e2fa5-ff68-416c-db0c-db00e3c4ee9a"
      },
      "source": [
        "train_model(linear1, 20, lr, params, train_dl, valid_dl)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: accuracy=0.8483\n",
            "2: accuracy=0.8742\n",
            "3: accuracy=0.8825\n",
            "4: accuracy=0.8878\n",
            "5: accuracy=0.8906\n",
            "6: accuracy=0.8942\n",
            "7: accuracy=0.8964\n",
            "8: accuracy=0.8986\n",
            "9: accuracy=0.8996\n",
            "10: accuracy=0.9011\n",
            "11: accuracy=0.9019\n",
            "12: accuracy=0.9028\n",
            "13: accuracy=0.9036\n",
            "14: accuracy=0.9045\n",
            "15: accuracy=0.9053\n",
            "16: accuracy=0.9058\n",
            "17: accuracy=0.9065\n",
            "18: accuracy=0.9081\n",
            "19: accuracy=0.9089\n",
            "20: accuracy=0.9094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kJOOoeQt23b"
      },
      "source": [
        "# A 2-layer simple network using SDG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWsTTl7zQ1b1"
      },
      "source": [
        "def simple_net(xb, parmas):\n",
        "    w1, b1, w2, b2 = params\n",
        "    res = xb@w1 + b1\n",
        "    res = res.max(torch.tensor(0.0))\n",
        "    res = res@w2 + b2\n",
        "    return res"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqqPD-cqhXKp"
      },
      "source": [
        "lr = 1\n",
        "w1 = init_params((28*28, 256))\n",
        "b1 = init_params(256)\n",
        "w2 = init_params((256, 10))\n",
        "b2 = init_params(10)\n",
        "params = w1, b1, w2, b2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVW5SOvZhoAn",
        "outputId": "ab030190-d6d1-49b4-8c56-f3152f32384f"
      },
      "source": [
        "train_model(simple_net, 20, lr, params, train_dl, valid_dl)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: accuracy=0.8092\n",
            "2: accuracy=0.8690\n",
            "3: accuracy=0.8871\n",
            "4: accuracy=0.8980\n",
            "5: accuracy=0.9043\n",
            "6: accuracy=0.9091\n",
            "7: accuracy=0.9122\n",
            "8: accuracy=0.9156\n",
            "9: accuracy=0.9192\n",
            "10: accuracy=0.9217\n",
            "11: accuracy=0.9244\n",
            "12: accuracy=0.9276\n",
            "13: accuracy=0.9289\n",
            "14: accuracy=0.9310\n",
            "15: accuracy=0.9329\n",
            "16: accuracy=0.9355\n",
            "17: accuracy=0.9356\n",
            "18: accuracy=0.9373\n",
            "19: accuracy=0.9370\n",
            "20: accuracy=0.9373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK3r1XOnhvNi"
      },
      "source": [
        "References:\n",
        "*   [Neural Network From Scratch with NumPy and MNIST](https://mlfromscratch.com/neural-network-tutorial/#/)\n",
        "*   [The fastai book chapter 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb)"
      ]
    }
  ]
}